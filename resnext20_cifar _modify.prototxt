
name: "resneXt_cifar10"

layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 32
    mean_file: "/home/zhanglong/caffe/examples/resnext/cifar10_40x40_lmdb/mean_40.binaryproto"
    mirror:true
  }
  data_param {
    source: "/home/zhanglong/caffe/examples/resnext/cifar10_40x40_lmdb/cifar10_train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/zhanglong/caffe/examples/resnext/cifar10_40x40_lmdb/mean.binaryproto"
  }
  data_param {
    source: "/home/zhanglong/caffe/examples/resnext/cifar10_40x40_lmdb/cifar10_test_lmdb"
    batch_size: 32
    backend: LMDB
  }
}

layer {
  name: "bn0"
  type: "BatchNorm"
  bottom: "data"
  top: "data"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}


layer {
  name: "conv0"
  type: "Convolution"
  bottom: "data"
  top: "conv0"
  convolution_param { 
     num_output: 16
     kernel_size: 3
     stride: 1
     pad: 1
     bias_term: true
  }
}



layer {
  name: "scale_bn0"
  bottom: "conv0"
  top: "conv0"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}

#layer {
#  name: "relu0"
#  type: "ReLU"
#  bottom: "conv0"
#  top: "conv0"
#}

#layer {
#  name: "pooling0"
#  type: "Pooling"
#  bottom: "conv0"
#  top: "pooling0"
#  pooling_param {
#     pool: MAX
#     kernel_size: 3
#     stride: 2
#  }
#}

layer {
  name: "stage1_unit1_conv1"
  type: "Convolution"
  bottom: "conv0"
  top: "stage1_unit1_conv1"
  convolution_param { 
     num_output: 16
     kernel_size: 3
     stride: 1
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage1_unit1_bn1"
  type: "BatchNorm"
  bottom: "stage1_unit1_conv1"
  top: "stage1_unit1_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage1_unit1_bn1"
  bottom: "stage1_unit1_conv1"
  top: "stage1_unit1_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}

layer {
  name: "stage1_unit1_relu1"
  type: "ReLU"
  bottom: "stage1_unit1_conv1"
  top: "stage1_unit1_conv1"
}

layer {
  name: "stage1_unit1_conv2"
  type: "Convolution"
  bottom: "stage1_unit1_conv1"
  top: "stage1_unit1_conv2"
  convolution_param { 
     num_output: 16
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage1_unit1_bn2"
  type: "BatchNorm"
  bottom: "stage1_unit1_conv2"
  top: "stage1_unit1_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage1_unit1_bn2"
  bottom: "stage1_unit1_conv2"
  top: "stage1_unit1_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}


layer {
  name: "stage1_unit1_conv3"
  type: "Convolution"
  bottom: "conv0"
  top: "stage1_unit1_conv3"
  convolution_param { 
     num_output: 16
     kernel_size: 1
     stride: 1
     pad: 0
     bias_term: true
  }
}

layer {
  name: "stage1_unit1_bn3"
  type: "BatchNorm"
  bottom: "stage1_unit1_conv3"
  top: "stage1_unit1_conv3"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage1_unit1_bn3"
  bottom: "stage1_unit1_conv3"
  top: "stage1_unit1_conv3"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}


layer {
  name: "stage1_unit1_plus"
  type: "Eltwise"
  bottom: "stage1_unit1_conv3"
  bottom: "stage1_unit1_conv2"
  top: "stage1_unit1_plus"
  eltwise_param {
     operation: SUM
  }
}

layer {
  name: "stage1_unit1_relu"
  type: "ReLU"
  bottom: "stage1_unit1_plus"
  top: "stage1_unit1_plus"
}

layer {
  name: "stage1_unit2_conv1"
  type: "Convolution"
  bottom: "stage1_unit1_plus"
  top: "stage1_unit2_conv1"
  convolution_param { 
     num_output: 16
     kernel_size: 3
     stride: 1
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage1_unit2_bn1"
  type: "BatchNorm"
  bottom: "stage1_unit2_conv1"
  top: "stage1_unit2_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage1_unit2_bn1"
  bottom: "stage1_unit2_conv1"
  top: "stage1_unit2_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}

layer {
  name: "stage1_unit2_relu1"
  type: "ReLU"
  bottom: "stage1_unit2_conv1"
  top: "stage1_unit2_conv1"
}

layer {
  name: "stage1_unit2_conv2"
  type: "Convolution"
  bottom: "stage1_unit2_conv1"
  top: "stage1_unit2_conv2"
  convolution_param { 
     num_output: 16
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage1_unit2_bn2"
  type: "BatchNorm"
  bottom: "stage1_unit2_conv2"
  top: "stage1_unit2_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage1_unit2_bn2"
  bottom: "stage1_unit2_conv2"
  top: "stage1_unit2_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}



layer {
  name: "stage1_unit2_plus"
  type: "Eltwise"
  bottom: "stage1_unit1_plus"
  bottom: "stage1_unit2_conv2"
  top: "stage1_unit2_plus"
  eltwise_param {
     operation: SUM
  }
}

layer {
  name: "stage1_unit2_relu"
  type: "ReLU"
  bottom: "stage1_unit2_plus"
  top: "stage1_unit2_plus"
}

layer {
  name: "stage1_unit3_conv1"
  type: "Convolution"
  bottom: "stage1_unit2_plus"
  top: "stage1_unit3_conv1"
  convolution_param { 
     num_output: 16
     kernel_size: 3
     stride: 1
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage1_unit3_bn1"
  type: "BatchNorm"
  bottom: "stage1_unit3_conv1"
  top: "stage1_unit3_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage1_unit3_bn1"
  bottom: "stage1_unit3_conv1"
  top: "stage1_unit3_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}

layer {
  name: "stage1_unit3_relu1"
  type: "ReLU"
  bottom: "stage1_unit3_conv1"
  top: "stage1_unit3_conv1"
}

layer {
  name: "stage1_unit3_conv2"
  type: "Convolution"
  bottom: "stage1_unit3_conv1"
  top: "stage1_unit3_conv2"
  convolution_param { 
     num_output: 16
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage1_unit3_bn2"
  type: "BatchNorm"
  bottom: "stage1_unit3_conv2"
  top: "stage1_unit3_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage1_unit3_bn2"
  bottom: "stage1_unit3_conv2"
  top: "stage1_unit3_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}


layer {
  name: "stage1_unit3_plus"
  type: "Eltwise"
  bottom: "stage1_unit2_plus"
  bottom: "stage1_unit3_conv2"
  top: "stage1_unit3_plus"
  eltwise_param {
     operation: SUM
  }
}

layer {
  name: "stage1_unit3_relu"
  type: "ReLU"
  bottom: "stage1_unit3_plus"
  top: "stage1_unit3_plus"
}

layer {
  name: "stage2_unit1_conv1"
  type: "Convolution"
  bottom: "stage1_unit3_plus"
  top: "stage2_unit1_conv1"
  convolution_param { 
     num_output: 32
     kernel_size: 3
     stride: 2
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage2_unit1_bn1"
  type: "BatchNorm"
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage2_unit1_bn1"
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}

layer {
  name: "stage2_unit1_relu1"
  type: "ReLU"
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_conv1"
}

layer {
  name: "stage2_unit1_conv2"
  type: "Convolution"
  bottom: "stage2_unit1_conv1"
  top: "stage2_unit1_conv2"
  convolution_param { 
     num_output: 32
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage2_unit1_bn2"
  type: "BatchNorm"
  bottom: "stage2_unit1_conv2"
  top: "stage2_unit1_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage2_unit1_bn2"
  bottom: "stage2_unit1_conv2"
  top: "stage2_unit1_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}


layer {
  name: "stage2_unit1_sc"
  type: "Convolution"
  bottom: "stage1_unit3_plus"
  top: "stage2_unit1_sc"
  convolution_param { 
     num_output: 32
     kernel_size: 1
     stride: 2
     pad: 0
     bias_term: true
  }
}

layer {
  name: "stage2_unit1_sc_bn"
  type: "BatchNorm"
  bottom: "stage2_unit1_sc"
  top: "stage2_unit1_sc"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage2_unit1_sc_bn"
  bottom: "stage2_unit1_sc"
  top: "stage2_unit1_sc"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}

layer {
  name: "stage2_unit1_plus"
  type: "Eltwise"
  bottom: "stage2_unit1_sc"
  bottom: "stage2_unit1_conv2"
  top: "stage2_unit1_plus"
  eltwise_param {
     operation: SUM
  }
}

layer {
  name: "stage2_unit1_relu"
  type: "ReLU"
  bottom: "stage2_unit1_plus"
  top: "stage2_unit1_plus"
}

layer {
  name: "stage2_unit2_conv1"
  type: "Convolution"
  bottom: "stage2_unit1_plus"
  top: "stage2_unit2_conv1"
  convolution_param { 
     num_output: 32
     kernel_size: 3
     stride: 1
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage2_unit2_bn1"
  type: "BatchNorm"
  bottom: "stage2_unit2_conv1"
  top: "stage2_unit2_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage2_unit2_bn1"
  bottom: "stage2_unit2_conv1"
  top: "stage2_unit2_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}

layer {
  name: "stage2_unit2_relu1"
  type: "ReLU"
  bottom: "stage2_unit2_conv1"
  top: "stage2_unit2_conv1"
}

layer {
  name: "stage2_unit2_conv2"
  type: "Convolution"
  bottom: "stage2_unit2_conv1"
  top: "stage2_unit2_conv2"
  convolution_param { 
     num_output: 32
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage2_unit2_bn2"
  type: "BatchNorm"
  bottom: "stage2_unit2_conv2"
  top: "stage2_unit2_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage2_unit2_bn2"
  bottom: "stage2_unit2_conv2"
  top: "stage2_unit2_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}



layer {
  name: "stage2_unit2_plus"
  type: "Eltwise"
  bottom: "stage2_unit1_plus"
  bottom: "stage2_unit2_conv2"
  top: "stage2_unit2_plus"
  eltwise_param {
     operation: SUM
  }
}

layer {
  name: "stage2_unit2_relu"
  type: "ReLU"
  bottom: "stage2_unit2_plus"
  top: "stage2_unit2_plus"
}

layer {
  name: "stage2_unit3_conv1"
  type: "Convolution"
  bottom: "stage2_unit2_plus"
  top: "stage2_unit3_conv1"
  convolution_param { 
     num_output: 32
     kernel_size: 3
     stride: 1
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage2_unit3_bn1"
  type: "BatchNorm"
  bottom: "stage2_unit3_conv1"
  top: "stage2_unit3_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage2_unit3_bn1"
  bottom: "stage2_unit3_conv1"
  top: "stage2_unit3_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}

layer {
  name: "stage2_unit3_relu1"
  type: "ReLU"
  bottom: "stage2_unit3_conv1"
  top: "stage2_unit3_conv1"
}

layer {
  name: "stage2_unit3_conv2"
  type: "Convolution"
  bottom: "stage2_unit3_conv1"
  top: "stage2_unit3_conv2"
  convolution_param { 
     num_output: 32
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage2_unit3_bn2"
  type: "BatchNorm"
  bottom: "stage2_unit3_conv2"
  top: "stage2_unit3_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage2_unit3_bn2"
  bottom: "stage2_unit3_conv2"
  top: "stage2_unit3_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}


layer {
  name: "stage2_unit3_plus"
  type: "Eltwise"
  bottom: "stage2_unit2_plus"
  bottom: "stage2_unit3_conv2"
  top: "stage2_unit3_plus"
  eltwise_param {
     operation: SUM
  }
}

layer {
  name: "stage2_unit3_relu"
  type: "ReLU"
  bottom: "stage2_unit3_plus"
  top: "stage2_unit3_plus"
}



layer {
  name: "stage3_unit1_conv1"
  type: "Convolution"
  bottom: "stage2_unit3_plus"
  top: "stage3_unit1_conv1"
  convolution_param { 
     num_output: 64
     kernel_size: 3
     stride: 2
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage3_unit1_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage3_unit1_bn1"
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}

layer {
  name: "stage3_unit1_relu1"
  type: "ReLU"
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_conv1"
}

layer {
  name: "stage3_unit1_conv2"
  type: "Convolution"
  bottom: "stage3_unit1_conv1"
  top: "stage3_unit1_conv2"
  convolution_param { 
     num_output: 64
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage3_unit1_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit1_conv2"
  top: "stage3_unit1_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage3_unit1_bn2"
  bottom: "stage3_unit1_conv2"
  top: "stage3_unit1_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}



layer {
  name: "stage3_unit1_sc"
  type: "Convolution"
  bottom: "stage2_unit3_plus"
  top: "stage3_unit1_sc"
  convolution_param { 
     num_output: 64
     kernel_size: 1
     stride: 2
     pad: 0
     bias_term: true
  }
}

layer {
  name: "stage3_unit1_sc_bn"
  type: "BatchNorm"
  bottom: "stage3_unit1_sc"
  top: "stage3_unit1_sc"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage3_unit1_sc_bn"
  bottom: "stage3_unit1_sc"
  top: "stage3_unit1_sc"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}

layer {
  name: "stage3_unit1_plus"
  type: "Eltwise"
  bottom: "stage3_unit1_sc"
  bottom: "stage3_unit1_conv2"
  top: "stage3_unit1_plus"
  eltwise_param {
     operation: SUM
  }
}

layer {
  name: "stage3_unit1_relu"
  type: "ReLU"
  bottom: "stage3_unit1_plus"
  top: "stage3_unit1_plus"
}

layer {
  name: "stage3_unit2_conv1"
  type: "Convolution"
  bottom: "stage3_unit1_plus"
  top: "stage3_unit2_conv1"
  convolution_param { 
     num_output: 64
     kernel_size: 3
     stride: 1
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage3_unit2_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit2_conv1"
  top: "stage3_unit2_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage3_unit2_bn1"
  bottom: "stage3_unit2_conv1"
  top: "stage3_unit2_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}

layer {
  name: "stage3_unit2_relu1"
  type: "ReLU"
  bottom: "stage3_unit2_conv1"
  top: "stage3_unit2_conv1"
}

layer {
  name: "stage3_unit2_conv2"
  type: "Convolution"
  bottom: "stage3_unit2_conv1"
  top: "stage3_unit2_conv2"
  convolution_param { 
     num_output: 64
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage3_unit2_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit2_conv2"
  top: "stage3_unit2_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage3_unit2_bn2"
  bottom: "stage3_unit2_conv2"
  top: "stage3_unit2_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}



layer {
  name: "stage3_unit2_plus"
  type: "Eltwise"
  bottom: "stage3_unit1_plus"
  bottom: "stage3_unit2_conv2"
  top: "stage3_unit2_plus"
  eltwise_param {
     operation: SUM
  }
}

layer {
  name: "stage3_unit2_relu"
  type: "ReLU"
  bottom: "stage3_unit2_plus"
  top: "stage3_unit2_plus"
}

layer {
  name: "stage3_unit3_conv1"
  type: "Convolution"
  bottom: "stage3_unit2_plus"
  top: "stage3_unit3_conv1"
  convolution_param { 
     num_output: 64
     kernel_size: 3
     stride: 1
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage3_unit3_bn1"
  type: "BatchNorm"
  bottom: "stage3_unit3_conv1"
  top: "stage3_unit3_conv1"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage3_unit3_bn1"
  bottom: "stage3_unit3_conv1"
  top: "stage3_unit3_conv1"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}

layer {
  name: "stage3_unit3_relu1"
  type: "ReLU"
  bottom: "stage3_unit3_conv1"
  top: "stage3_unit3_conv1"
}

layer {
  name: "stage3_unit3_conv2"
  type: "Convolution"
  bottom: "stage3_unit3_conv1"
  top: "stage3_unit3_conv2"
  convolution_param { 
     num_output: 64
     kernel_size: 3
     stride: 1
     group: 32
     pad: 1
     bias_term: true
  }
}

layer {
  name: "stage3_unit3_bn2"
  type: "BatchNorm"
  bottom: "stage3_unit3_conv2"
  top: "stage3_unit3_conv2"
  batch_norm_param {
    use_global_stats: true
    eps: 2e-5
  }
}

layer {
  name: "scale_stage3_unit3_bn2"
  bottom: "stage3_unit3_conv2"
  top: "stage3_unit3_conv2"
  type: "Scale"
  scale_param {
        bias_term: true
  }
}



layer {
  name: "stage3_unit3_plus"
  type: "Eltwise"
  bottom: "stage3_unit2_plus"
  bottom: "stage3_unit3_conv2"
  top: "stage3_unit3_plus"
  eltwise_param {
     operation: SUM
  }
}

layer {
  name: "stage3_unit3_relu"
  type: "ReLU"
  bottom: "stage3_unit3_plus"
  top: "stage3_unit3_plus"
}

layer {
  name: "pool1"
  type: "Pooling"
  bottom: "stage3_unit3_plus"
  top: "pool1"
  pooling_param {
     global_pooling : true
     pool: AVE
  }
}

layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool1"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}

layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc1"
  bottom: "label"
  top: "loss"
}

#layer {
#  name:"softmax"
#  type:"Softmax"
#  bottom:"fc1"
#  top:"softmax"
#}

layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
